{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db309e-3114-4477-8203-381a5bef62dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddb8908-a16d-4c30-945c-3fe8302d35ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = pd.read_csv('df_grouped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2124d0-9dbf-4d28-b0d6-ea245697a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Выбираем 1000 случайных чатов с ошибкой\n",
    "df_error = df_grouped[df_grouped['error'] == 1].sample(n=500, random_state=42)\n",
    "\n",
    "# 2. Выбираем 1000 случайных чатов без ошибки\n",
    "df_no_error = df_grouped[df_grouped['error'] == 0].sample(n=500, random_state=42)\n",
    "\n",
    "# Объединяем обе выборки в один датафрейм\n",
    "df_gpt = pd.concat([df_error, df_no_error]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(df_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43006123-4b60-4292-8da1-29374dd52e8a",
   "metadata": {},
   "source": [
    "### GPT 4o zero shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2c60b6-ef73-4076-bae7-311be75642c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- НАСТРОЙКИ API ---\n",
    "AUTH_URL = '...'\n",
    "PROXY_URL = '...'\n",
    "MODEL = 'gpt-4o'\n",
    "\n",
    "# --- Авторизация ---\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    data = {\"username\": username, \"password\": password}\n",
    "    response = requests.post(AUTH_URL, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['access_token']\n",
    "\n",
    "# --- Отправка одного запроса ---\n",
    "def send_prompt(prompt: str, access_token: str) -> str:\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'x-proxy-mask-critical-data': '1'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    response = requests.post(PROXY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "# --- Формирование промпта ---\n",
    "def make_prompt(chat_text: str) -> str:\n",
    "    return (\n",
    "        \"Ниже приведен чат между клиентом и оператором службы поддержки банка. \"\n",
    "        \"Определи, допустил ли оператор ошибку: **Не сгладил негатив клиента**. \"\n",
    "        \"Чат состоит из нескольких сообщений. Перед началом сообщения указано от кого оно. \"\n",
    "        \"Проверь чат на наличие ошибки и ответь строго 0 (если считаешь что в чате нет ошибки) или 1 (если считаешь что ошибка была).\\n\\n\"\n",
    "        \"Чат:\\n\"\n",
    "        f\"{chat_text}\\n\\n\"\n",
    "        \"Ответ:\"\n",
    "    )\n",
    "\n",
    "# --- Безопасное извлечение ответа 0 или 1 ---\n",
    "def extract_prediction(response: str) -> int:\n",
    "    match = re.search(r'\\b[01]\\b', response)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None  # если нет нормального ответа\n",
    "\n",
    "# --- Основная функция ---\n",
    "def evaluate_gpt(df_gpt, username, password, limit=None, delay=1.5):\n",
    "    token = get_access_token(username, password)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    skipped_chats = 0  # счётчик пропущенных чатов\n",
    "\n",
    "    for i, row in df_gpt.iterrows():\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        \n",
    "        prompt = make_prompt(row['message_txt'])\n",
    "\n",
    "        try:\n",
    "            response = send_prompt(prompt, token)\n",
    "            prediction = extract_prediction(response)\n",
    "\n",
    "            # Только если извлечён валидный ответ (0 или 1)\n",
    "            if prediction is not None:\n",
    "                true_labels.append(row['error'])\n",
    "                predicted_labels.append(prediction)\n",
    "                print(f\"[{i+1}/{len(df_gpt)}] true={row['error']} | predicted={prediction}\")\n",
    "            else:\n",
    "                print(f\" Невалидный ответ от GPT на чате {i}, чат пропущен.\")\n",
    "                skipped_chats += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\" Ошибка на чате {i}: {e}\")\n",
    "            skipped_chats += 1\n",
    "            continue\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    if not true_labels:\n",
    "        print(\"\\n Нет успешно обработанных чатов. Метрики посчитать невозможно.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Выводим метрики по каждому классу\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4, target_names=[\"no_error\", \"error\"]))\n",
    "\n",
    "    print(f\"\\nПропущено чатов из-за ошибок или невалидных ответов: {skipped_chats}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'true_error': true_labels,\n",
    "        'predicted_error': predicted_labels\n",
    "    })\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == '__main__':\n",
    "    username = Z_ENV_LOGIN_GPT  # или os.getenv(\"Z_ENV_LOGIN_GPT\")\n",
    "    password = Z_ENV_PASS_GPT   # или os.getenv(\"Z_ENV_PASS_GPT\")\n",
    "\n",
    "    results_df = evaluate_gpt(df_gpt, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e05e9c-202f-41f4-b74e-ac8d3cda082d",
   "metadata": {},
   "source": [
    "### GPT o3 few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dc727-54c0-40c8-950d-68503bce454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- НАСТРОЙКИ API ---\n",
    "AUTH_URL = 'https://openai-proxy.tcsbank.ru/auth/v1/token'\n",
    "PROXY_URL = 'https://openai-proxy.tcsbank.ru/public/v1/chat/completions'\n",
    "MODEL = 'o3'\n",
    "\n",
    "# --- Авторизация ---\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    data = {\"username\": username, \"password\": password}\n",
    "    response = requests.post(AUTH_URL, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['access_token']\n",
    "\n",
    "# --- Отправка одного запроса ---\n",
    "def send_prompt(prompt: str, access_token: str) -> str:\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'x-proxy-mask-critical-data': '1'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    response = requests.post(PROXY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "# --- Формирование промпта ---\n",
    "def make_prompt(chat_text: str) -> str:\n",
    "    return (\n",
    "        \"Ниже приведен чат между клиентом и оператором службы поддержки банка. \"\n",
    "        \"Определи, допустил ли оператор ошибку: **Не сгладил негатив клиента**. \"\n",
    "        \"Чат состоит из нескольких сообщений. Перед началом сообщения указано от кого оно. \"\n",
    "        \"Проверь чат на наличие ошибки и ответь строго 0 (если считаешь что в чате нет ошибки) или 1 (если считаешь что ошибка была).\\n\\n\"\n",
    "        \"Чат:\\n\"\n",
    "        f\"{chat_text}\\n\\n\"\n",
    "        \"Ответ:\"\n",
    "    )\n",
    "\n",
    "# --- Безопасное извлечение ответа 0 или 1 ---\n",
    "def extract_prediction(response: str) -> int:\n",
    "    match = re.search(r'\\b[01]\\b', response)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None  # если нет нормального ответа\n",
    "\n",
    "# --- Основная функция ---\n",
    "def evaluate_gpt(df_gpt, username, password, limit=None, delay=1.5):\n",
    "    token = get_access_token(username, password)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    skipped_chats = 0  # счётчик пропущенных чатов\n",
    "\n",
    "    for i, row in df_gpt.iterrows():\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        \n",
    "        prompt = make_prompt(row['message_txt'])\n",
    "\n",
    "        try:\n",
    "            response = send_prompt(prompt, token)\n",
    "            prediction = extract_prediction(response)\n",
    "\n",
    "            # Только если извлечён валидный ответ (0 или 1)\n",
    "            if prediction is not None:\n",
    "                true_labels.append(row['error'])\n",
    "                predicted_labels.append(prediction)\n",
    "                print(f\"[{i+1}/{len(df_gpt)}] true={row['error']} | predicted={prediction}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Невалидный ответ от GPT на чате {i}, чат пропущен.\")\n",
    "                skipped_chats += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка на чате {i}: {e}\")\n",
    "            skipped_chats += 1\n",
    "            continue\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    if not true_labels:\n",
    "        print(\"\\n⚠️ Нет успешно обработанных чатов. Метрики посчитать невозможно.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Выводим метрики по каждому классу\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4, target_names=[\"no_error\", \"error\"]))\n",
    "\n",
    "    print(f\"\\nПропущено чатов из-за ошибок или невалидных ответов: {skipped_chats}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'true_error': true_labels,\n",
    "        'predicted_error': predicted_labels\n",
    "    })\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == '__main__':\n",
    "    username = Z_ENV_LOGIN_GPT  # или os.getenv(\"Z_ENV_LOGIN_GPT\")\n",
    "    password = Z_ENV_PASS_GPT   # или os.getenv(\"Z_ENV_PASS_GPT\")\n",
    "\n",
    "    results_df = evaluate_gpt(df_gpt, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338c40b-3978-407c-a61e-77d3476f3a7a",
   "metadata": {},
   "source": [
    "### GPT 4o few shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38799592-c5d5-4d29-8b7b-3ab927fde574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- НАСТРОЙКИ API ---\n",
    "AUTH_URL = '...'\n",
    "PROXY_URL = '...'\n",
    "MODEL = 'gpt-4o'\n",
    "\n",
    "# --- Авторизация ---\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    data = {\"username\": username, \"password\": password}\n",
    "    response = requests.post(AUTH_URL, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['access_token']\n",
    "\n",
    "# --- Отправка одного запроса ---\n",
    "def send_prompt(prompt: str, access_token: str) -> str:\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'x-proxy-mask-critical-data': '1'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    response = requests.post(PROXY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "# --- Формирование промпта ---\n",
    "def make_prompt(chat_text: str) -> str:\n",
    "    return (\n",
    "        \"You are the world’s most accurate expert in analyzing customer support chats for emotional intelligence errors. \"\n",
    "        \"Your specific task is to detect whether the support operator **failed to defuse the customer's negativity** during the interaction.\\n\\n\"\n",
    "        \"Definition of the error:\\n\"\n",
    "        \"- The operator does **not** apologize when the customer is clearly upset or frustrated.\\n\"\n",
    "        \"- The operator does **not** attempt to solve the problem or reassure the customer.\\n\"\n",
    "        \"- The operator shows **no empathy** when the customer expresses dissatisfaction.\\n\\n\"\n",
    "        \"- or the operator does **not** smooth a client's negative any other way.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"- <client> Ненавижу ваш банк! Где мой кэшбек?? <operator> Придет в дату выписки. - The operator answered, but did **not** smooth the customer's negative about a bank - it is a mistake.\\n\"\n",
    "        \"- <client> Почему мне отказали в кредитке?? Терпеть вас не могу. <operator> Ни в коем случае не хотели вас расстроить! Понимаю, как важно иметь под рукой кредитную карту. Мы пересмотрим наше решение. - The operator smoothed the client's negative, apologizing for the situation - there is no mistake.\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Analyze the full conversation (given on Russian language) carefully.\\n\"\n",
    "        \"- If the operator **makes no effort** to calm the customer when there is visible negativity (according to instructions), return `1`.\\n\"\n",
    "        \"- If the operator **acknowledges the customer's frustration**, tries to smooth his negative, or there is no negative from client at all, return `0`.\\n\\n\"\n",
    "        \"Return only a single digit: `1` (error detected) or `0` (no error).\\n\\n\"\n",
    "        \"Chat:\\n\"\n",
    "        f\"{chat_text}\\n\\n\"\n",
    "        \"Your answer:\"\n",
    "    )\n",
    "\n",
    "# --- Безопасное извлечение ответа 0 или 1 ---\n",
    "def extract_prediction(response: str) -> int:\n",
    "    match = re.search(r'\\b[01]\\b', response)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None  # если нет нормального ответа\n",
    "\n",
    "# --- Основная функция ---\n",
    "def evaluate_gpt(df_gpt, username, password, limit=None, delay=1.5):\n",
    "    token = get_access_token(username, password)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    skipped_chats = 0  # счётчик пропущенных чатов\n",
    "\n",
    "    for i, row in df_gpt.iterrows():\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        \n",
    "        prompt = make_prompt(row['message_txt'])\n",
    "\n",
    "        try:\n",
    "            response = send_prompt(prompt, token)\n",
    "            prediction = extract_prediction(response)\n",
    "\n",
    "            # Только если извлечён валидный ответ (0 или 1)\n",
    "            if prediction is not None:\n",
    "                true_labels.append(row['error'])\n",
    "                predicted_labels.append(prediction)\n",
    "                print(f\"[{i+1}/{len(df_gpt)}] true={row['error']} | predicted={prediction}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Невалидный ответ от GPT на чате {i}, чат пропущен.\")\n",
    "                skipped_chats += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка на чате {i}: {e}\")\n",
    "            skipped_chats += 1\n",
    "            continue\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    if not true_labels:\n",
    "        print(\"\\n⚠️ Нет успешно обработанных чатов. Метрики посчитать невозможно.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Выводим метрики по каждому классу\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4, target_names=[\"no_error\", \"error\"]))\n",
    "\n",
    "    print(f\"\\nПропущено чатов из-за ошибок или невалидных ответов: {skipped_chats}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'true_error': true_labels,\n",
    "        'predicted_error': predicted_labels\n",
    "    })\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == '__main__':\n",
    "    username = Z_ENV_LOGIN_GPT  # или os.getenv(\"Z_ENV_LOGIN_GPT\")\n",
    "    password = Z_ENV_PASS_GPT   # или os.getenv(\"Z_ENV_PASS_GPT\")\n",
    "\n",
    "    results_df = evaluate_gpt(df_gpt, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a341ff-4e40-4a5c-82b0-a24d4e8e5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# --- НАСТРОЙКИ API ---\n",
    "AUTH_URL = 'https://openai-proxy.tcsbank.ru/auth/v1/token'\n",
    "PROXY_URL = 'https://openai-proxy.tcsbank.ru/public/v1/chat/completions'\n",
    "MODEL = 'o3'\n",
    "\n",
    "# --- Авторизация ---\n",
    "def get_access_token(username: str, password: str) -> str:\n",
    "    data = {\"username\": username, \"password\": password}\n",
    "    response = requests.post(AUTH_URL, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['access_token']\n",
    "\n",
    "# --- Отправка одного запроса ---\n",
    "def send_prompt(prompt: str, access_token: str) -> str:\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {access_token}',\n",
    "        'x-proxy-mask-critical-data': '1'\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "    }\n",
    "    response = requests.post(PROXY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()['choices'][0]['message']['content']\n",
    "\n",
    "# --- Формирование промпта ---\n",
    "def make_prompt(chat_text: str) -> str:\n",
    "    return (\n",
    "        \"You are the world’s most accurate expert in analyzing customer support chats for emotional intelligence errors. \"\n",
    "        \"Your specific task is to detect whether the support operator **failed to defuse the customer's negativity** during the interaction.\\n\\n\"\n",
    "        \"Definition of the error:\\n\"\n",
    "        \"- The operator does **not** apologize when the customer is clearly upset or frustrated.\\n\"\n",
    "        \"- The operator does **not** attempt to solve the problem or reassure the customer.\\n\"\n",
    "        \"- The operator shows **no empathy** when the customer expresses dissatisfaction.\\n\\n\"\n",
    "        \"- or the operator does **not** smooth a client's negative any other way.\\n\\n\"\n",
    "        \"Examples:\\n\"\n",
    "        \"- <client> Ненавижу ваш банк! Где мой кэшбек?? <operator> Придет в дату выписки. - The operator answered, but did **not** smooth the customer's negative about a bank - it is a mistake.\\n\"\n",
    "        \"- <client> Почему мне отказали в кредитке?? Терпеть вас не могу. <operator> Ни в коем случае не хотели вас расстроить! Понимаю, как важно иметь под рукой кредитную карту. Мы пересмотрим наше решение. - The operator smoothed the client's negative, apologizing for the situation - there is no mistake.\\n\"\n",
    "        \"Instructions:\\n\"\n",
    "        \"- Analyze the full conversation (given on Russian language) carefully.\\n\"\n",
    "        \"- If the operator **makes no effort** to calm the customer when there is visible negativity (according to instructions), return `1`.\\n\"\n",
    "        \"- If the operator **acknowledges the customer's frustration**, tries to smooth his negative, or there is no negative from client at all, return `0`.\\n\\n\"\n",
    "        \"Return only a single digit: `1` (error detected) or `0` (no error).\\n\\n\"\n",
    "        \"Chat:\\n\"\n",
    "        f\"{chat_text}\\n\\n\"\n",
    "        \"Your answer:\"\n",
    "    )\n",
    "\n",
    "# --- Безопасное извлечение ответа 0 или 1 ---\n",
    "def extract_prediction(response: str) -> int:\n",
    "    match = re.search(r'\\b[01]\\b', response)\n",
    "    if match:\n",
    "        return int(match.group())\n",
    "    return None  # если нет нормального ответа\n",
    "\n",
    "# --- Основная функция ---\n",
    "def evaluate_gpt(df_gpt, username, password, limit=None, delay=1.5):\n",
    "    token = get_access_token(username, password)\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    skipped_chats = 0  # счётчик пропущенных чатов\n",
    "\n",
    "    for i, row in df_gpt.iterrows():\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        \n",
    "        prompt = make_prompt(row['message_txt'])\n",
    "\n",
    "        try:\n",
    "            response = send_prompt(prompt, token)\n",
    "            prediction = extract_prediction(response)\n",
    "\n",
    "            # Только если извлечён валидный ответ (0 или 1)\n",
    "            if prediction is not None:\n",
    "                true_labels.append(row['error'])\n",
    "                predicted_labels.append(prediction)\n",
    "                print(f\"[{i+1}/{len(df_gpt)}] true={row['error']} | predicted={prediction}\")\n",
    "            else:\n",
    "                print(f\"⚠️ Невалидный ответ от GPT на чате {i}, чат пропущен.\")\n",
    "                skipped_chats += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ошибка на чате {i}: {e}\")\n",
    "            skipped_chats += 1\n",
    "            continue\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    if not true_labels:\n",
    "        print(\"\\n⚠️ Нет успешно обработанных чатов. Метрики посчитать невозможно.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Выводим метрики по каждому классу\n",
    "    print(\"\\n=== Classification Report ===\")\n",
    "    print(classification_report(true_labels, predicted_labels, digits=4, target_names=[\"no_error\", \"error\"]))\n",
    "\n",
    "    print(f\"\\nПропущено чатов из-за ошибок или невалидных ответов: {skipped_chats}\")\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'true_error': true_labels,\n",
    "        'predicted_error': predicted_labels\n",
    "    })\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == '__main__':\n",
    "    username = Z_ENV_LOGIN_GPT  # или os.getenv(\"Z_ENV_LOGIN_GPT\")\n",
    "    password = Z_ENV_PASS_GPT   # или os.getenv(\"Z_ENV_PASS_GPT\")\n",
    "\n",
    "    results_df = evaluate_gpt(df_gpt, username, password)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
