{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f18d8-7dd5-43f4-91d7-4d3466c1cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e1373d-43b5-4112-9d7c-e76b98533eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810af8de-dc4b-41c4-9e9b-c871196d2f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "y_train = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d0440-6b2a-4a1c-b475-7b787d718d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = pd.read_csv('X_val.csv')\n",
    "y_val = pd.read_csv('y_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7c1b-8ca4-4229-bc30-6b80aa7c332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn scipy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295f399-cbbe-40d6-be10-368bb60c9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d911767-ef8a-4920-8843-a4c94c9a380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers==4.25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63081675-2796-43ef-b4fd-7da82e062e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0278adc-aff2-4ded-92e4-63ea7f42b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"  # Можно использовать 'gpt2-medium', 'EleutherAI/gpt-neo-125M' и др.\n",
    "num_labels = 2       # Количество классов для классификации\n",
    "batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Для классификации нам нужно добавить специальный токен для классификации\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033eac8-de76-4475-8c62-b2183ee28f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "dataset = load_data()\n",
    "tokenized_datasets = tokenize_data(tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4758961b-d010-40dd-82d9-0932c3914e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install accelerate==0.28.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e1be7-1032-4670-ae09-5fd397ce3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аргументы обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    metric_for_best_model='f1',\n",
    "    eval_strategy='epoch',\n",
    "    # save_strategy='best',\n",
    "    # load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"best\",\n",
    "    load_best_model_at_end=False,\n",
    "    learning_rate=learning_rate,\n",
    ")\n",
    "\n",
    "# Создание Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],  \n",
    "    eval_dataset=tokenized_datasets['val'],     \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21097485-05e9-47c4-a51c-840bcf7c8f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение\n",
    "trainer.train()\n",
    "\n",
    "# Оценка\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Результаты оценки: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19011e51-a84f-40aa-b227-3a6aff019506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e9f44-011d-4977-b0b2-f58455296bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "model_dir = \"results/checkpoint-10478\"\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Перевод модели в режим оценки\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24c253-10ed-456d-b295-49ff1724f79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Токенизация входного текста\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Получение предсказаний\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    return predictions.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ee152-13d1-44dd-8d65-3a18bb9f81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6db8e5e-f8bc-4cde-a2bb-3cb79327ff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Создайте DataLoader для тестового набора данных\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=8)\n",
    "\n",
    "# Получите предсказания\n",
    "all_preds_probas = []\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        all_preds_probas.extend(outputs.logits.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6906a487-5cb3-4feb-9369-e54a3046255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d929f1-0b69-4f21-96ea-6191872782b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = torch.sigmoid(torch.tensor(all_preds_probas)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863e5a4-eadf-4a84-a451-2a3a16d2f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "precision, recall, thr = precision_recall_curve(all_labels, preds_proba[:, 1])\n",
    "\n",
    "plt.plot(thr, precision[:-1], label='precision')\n",
    "plt.plot(thr, recall[:-1], label='recall')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8a5a47-ccf7-4d06-9aed-976e440a7302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, (preds_proba[:, 1] > 0.64) * 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4aca8-e0c4-40fa-a747-802ba248c267",
   "metadata": {},
   "source": [
    "### Data augmentation with back translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34611c0-2efe-472b-9a9c-94a9ade49696",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test.error.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bb4d91-498c-4b1e-9a68-8e9842b9fdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('train_back_translated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df67be1b-373d-43f4-b505-89f2f267ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48997477-52ef-446e-bdfa-12f4b7f89bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"  \n",
    "num_labels = 2       \n",
    "batch_size = 8\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64a63f-097e-4861-bf70-86d05fcfb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_data()\n",
    "tokenized_datasets = tokenize_data(tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2d62fc-db8e-4791-855e-b571067fb901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    metric_for_best_model='f1',\n",
    "    # eval_strategy='epoch',\n",
    "    # save_strategy='best',\n",
    "    # load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    learning_rate=learning_rate,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],  \n",
    "    eval_dataset=tokenized_datasets['val'],     \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479d566-5579-45ee-97e4-fa8d5cf7c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer.train()\n",
    "\n",
    "# Оценка\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Результаты оценки: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb7e03-8443-4c4f-95b0-6e2581b690ee",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d99718-9c66-469b-bb68-518471c38f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "model_dir = \"results/checkpoint-35385\"\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Перевод модели в режим оценки\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e07ff6f-b1e1-4c77-975b-16d967d4657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    # Токенизация входного текста\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # Получение предсказаний\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    return predictions.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11333447-de3c-482c-a930-a6c70fbf30ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4dd546-628c-4a79-9776-e35709f0313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Создайте DataLoader для тестового набора данных\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=8)\n",
    "\n",
    "# Получите предсказания\n",
    "all_preds_probas = []\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        all_preds_probas.extend(outputs.logits.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fad2a4-45e5-44c6-90b8-105544b99642",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf7d33-a07d-4fc9-957d-303cdaedc84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = torch.sigmoid(torch.tensor(all_preds_probas)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9b4a6d-6d5e-4a91-a780-eda40e5aa77b",
   "metadata": {},
   "source": [
    "### Duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c0c80-d5ee-468c-ab8b-031d893cfbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_duplication.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2727335-20df-40be-b6d6-66962b4cf0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.message_txt.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edb3e4c-746a-4a58-8d27-c361a5477124",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df.error.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7ba132-21a1-4e75-90cc-efbb8ae449e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"  # Можно использовать 'gpt2-medium', 'EleutherAI/gpt-neo-125M' и др.\n",
    "num_labels = 2       # Количество классов для классификации\n",
    "batch_size = 16\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "\n",
    "# Загрузка модели и токенизатора\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Для классификации нам нужно добавить специальный токен для классификации\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fe3a8-0ffa-48b5-b88b-7e472336bf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "dataset = load_data()\n",
    "tokenized_datasets = tokenize_data(tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86808213-1090-4e4f-af6c-d9319bc2ffab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Аргументы обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    metric_for_best_model='f1',\n",
    "    # eval_strategy='epoch',\n",
    "    # save_strategy='best',\n",
    "    # load_best_model_at_end=True,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=False,\n",
    "    learning_rate=learning_rate,\n",
    ")\n",
    "\n",
    "# Создание Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],  # Ограничение для примера\n",
    "    eval_dataset=tokenized_datasets['val'],     # Ограничение для примера\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "training_args.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507284f4-1972-45f8-a07f-92d1e94ab11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Обучение\n",
    "trainer.train()\n",
    "\n",
    "# Оценка\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Результаты оценки: {eval_results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335fa81c-417b-40ba-afb1-70410b1cd16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "import torch\n",
    "\n",
    "model_name = \"sberbank-ai/rugpt3small_based_on_gpt2\"\n",
    "model_dir = \"results/checkpoint-10617\"\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = GPT2ForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Перевод модели в режим оценки\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3d42c-ba4c-4372-800c-b3161a3ef743",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56268632-fb3c-4b30-b9ca-167db1f9868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Создайте DataLoader для тестового набора данных\n",
    "test_dataloader = DataLoader(tokenized_datasets['test'], batch_size=8)\n",
    "\n",
    "# Получите предсказания\n",
    "all_preds_probas = []\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        inputs = {key: val.to(model.device) for key, val in batch.items() if key != 'labels'}\n",
    "        labels = batch['labels'].to(model.device)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "        all_preds_probas.extend(outputs.logits.cpu().numpy())\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b9e02-696c-4022-b57e-76332367eb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba866a4-4549-4475-b608-49cd0e2c3f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_proba = torch.sigmoid(torch.tensor(all_preds_probas)).cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
